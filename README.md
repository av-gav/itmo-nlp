# itmo-nlp

Online course Natural Language Processing with Machine Learning

1. Выбираем задачу классификации, а конкретно - идентификации языка по фрагменту текста. Ограничимся языками, использующими кириллические алфавиты. Соответственно, нужно будет сформировать датасет с текстами на разных языках. Возможные источники для исходных текстов:
- Wikipedia (https://en.wikipedia.org) // можно попробовать датасеты из Tensorflow
- Tatoeba (https://attoeba.org) // данные можно получать с помощью https://pypi.org/project/tatoebatools/
- UDHR in Unicode (https://unicode.org/udhr) // есть модуль в NLTK, но можно и прямо с сайта (plaintext)
- CC-100: Monolingual Datasets from Web Crawl Data (https://data.statmt.org/cc-100)
- Коллекции текстов на малых языках (http://web-corpora.net/wsgi3/minorlangs/download)

2. Для векторизации предварительным вариантом выбираем преобразование текста в символы (возможно этого и хватит, особенно для базовой модели), для улучшения можно перейти к биграммам и триграммам (символьным), и создание частотной модели.

3. В качестве более продвинутого варианта предварительно рассматриваем TF-IDF.

4. Модель ML - для начала можно попробовать байесовский классификатор

5. Модель DL - как вариант - RNN/LSTM. Возможно получится напрямую подавать на вход коды символов, для каждого символа кириллицы отдельный вход (должно хватить 256 входов), большая глубина по времени не нужна, так что может быть даже LSTM не обязательно.
